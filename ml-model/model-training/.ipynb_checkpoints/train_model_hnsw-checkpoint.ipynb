{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import faiss \n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is downloaded from: https://grouplens.org/datasets/movielens/https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "nRowsRead = None # specify 'None' if want to read whole file\n",
    "# movie_metadata.csv has 5044 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "movies = pd.read_csv('../data/movie-lens-small/movies.csv', delimiter=',', nrows = nRowsRead)\n",
    "ratings = pd.read_csv('../data/movie-lens-small/ratings.csv', delimiter=',', nrows = nRowsRead)\n",
    "tags = pd.read_csv('../data/movie-lens-small/tags.csv', delimiter=',', nrows = nRowsRead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9742, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "display(movies.head(5))\n",
    "# display(ratings.head(5))\n",
    "# display(tags.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoder = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_titles_batch(titles, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(titles), batch_size):\n",
    "        batch = titles[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        outputs = encoder(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "        all_embeddings.append(embeddings)\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(titles) // batch_size + 1}\")\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/20\n",
      "Processed batch 2/20\n",
      "Processed batch 3/20\n",
      "Processed batch 4/20\n",
      "Processed batch 5/20\n",
      "Processed batch 6/20\n",
      "Processed batch 7/20\n",
      "Processed batch 8/20\n",
      "Processed batch 9/20\n",
      "Processed batch 10/20\n",
      "Processed batch 11/20\n",
      "Processed batch 12/20\n",
      "Processed batch 13/20\n",
      "Processed batch 14/20\n",
      "Processed batch 15/20\n",
      "Processed batch 16/20\n",
      "Processed batch 17/20\n",
      "Processed batch 18/20\n",
      "Processed batch 19/20\n",
      "Processed batch 20/20\n"
     ]
    }
   ],
   "source": [
    "# Assuming movies is a DataFrame with 'title' and 'movieId'\n",
    "batch_size = 512  # Adjust batch size as needed\n",
    "\n",
    "# Process titles in batches and create embeddings\n",
    "embeddings = encode_titles_batch(movies['title'].tolist(), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9742, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiatize index\n",
      "number of records to index: 9742\n",
      "Adding embeddings to the index...\n",
      "Embeddings added to the index.\n"
     ]
    }
   ],
   "source": [
    "def create_faiss_index(embeddings):    \n",
    "    d = embeddings.shape[1]  # dimension of embeddings\n",
    "    n = embeddings.shape[0]\n",
    "    print(\"Initiatize index\")\n",
    "    print(f'number of records to index: {n}')\n",
    "    index = faiss.IndexHNSWFlat(d, 32, faiss.METRIC_INNER_PRODUCT)\n",
    "    \n",
    "    print(\"Adding embeddings to the index...\")\n",
    "    index.add(embeddings)\n",
    "    print(\"Embeddings added to the index.\")\n",
    "\n",
    "    return index\n",
    "# Create FAISS index with these embeddings\n",
    "faiss_index = create_faiss_index(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a mapping of index to movie_id\n",
    "index_to_id = {i: (row['movieId'], row['title']) for i, row in movies[['movieId', 'title']].iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_index(query, k):\n",
    "#     query_embedding = encode_titles_batch([query])    \n",
    "#     distances, indices = faiss_index.search(query_embedding, k)\n",
    "    \n",
    "#     # Retrieve movie IDs for the indices\n",
    "#     return [(index_to_id[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "def search_index(query, k, faiss_index, index_to_id, tokenizer, encoder):\n",
    "    query_embedding = encode_query(query, tokenizer, encoder)\n",
    "    print(f\"DEBUG: calling faiss_index with {k}...\")\n",
    "    print(f\"DEBUG: query_embedding dimension...\")\n",
    "    print(query_embedding.shape)\n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "    print(f\"DEBUG: done calling faiss_index with {k}!\")\n",
    "\n",
    "    # Retrieve movie IDs for the indices\n",
    "    return [(index_to_id[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "\n",
    "def encode_query(query, tokenizer, encoder):\n",
    "    print(f\"DEBUG: encoding query: {query}...\")\n",
    "    inputs = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    outputs = encoder(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "    print(f\"DEBUG: done encoding query: {query}\")\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: encoding query: toy story...\n"
     ]
    }
   ],
   "source": [
    "# search_index('toy story', 5, faiss_index, index_to_id, tokenizer, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = \"../model-artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming index_to_id is your dictionary\n",
    "with open(f\"{path_prefix}/index_to_id.pickle\", 'wb') as handle:\n",
    "    pickle.dump(index_to_id, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(faiss_index, f'{path_prefix}/faiss_index.idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer and model\n",
    "encoder.save_pretrained(f\"{path_prefix}/bert_model\")\n",
    "tokenizer.save_pretrained(f\"{path_prefix}/bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # accessing directory structure\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import faiss \n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = \"../model-artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "faiss_index = faiss.read_index(f\"{path_prefix}/faiss_index.idx\")\n",
    "tokenizer = BertTokenizer.from_pretrained(f\"{path_prefix}/bert_model\")\n",
    "encoder = BertModel.from_pretrained(f\"{path_prefix}/bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_to_id.pickle', 'rb') as handle:\n",
    "    index_to_id = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(query, k):\n",
    "    query_embedding = encode_titles_batch([query])    \n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "    \n",
    "    # Retrieve movie IDs for the indices\n",
    "    return [(index_to_id[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "\n",
    "def encode_titles_batch(titles, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(titles), batch_size):\n",
    "        batch = titles[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        outputs = encoder(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "        all_embeddings.append(embeddings)\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(titles) // batch_size + 1}\")\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index('toy', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7181,
     "sourceId": 10279,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29271,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ml-model",
   "language": "python",
   "name": "ml-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
