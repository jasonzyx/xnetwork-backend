{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d2d138d-10dd-4ae8-94b6-92164d50ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de38649-a833-4699-bef3-936df380614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 0.7409, Validation Loss: 1.2138\n",
      "Epoch [2/100], Training Loss: 0.9021, Validation Loss: 1.2037\n",
      "Epoch [3/100], Training Loss: 0.7961, Validation Loss: 1.3315\n",
      "Epoch [4/100], Training Loss: 0.7466, Validation Loss: 1.1415\n",
      "Epoch [5/100], Training Loss: 0.7925, Validation Loss: 1.2470\n",
      "Epoch [6/100], Training Loss: 0.6768, Validation Loss: 1.1813\n",
      "Epoch [7/100], Training Loss: 1.0099, Validation Loss: 1.1311\n",
      "Epoch [8/100], Training Loss: 0.5760, Validation Loss: 1.1594\n",
      "Epoch [9/100], Training Loss: 0.6223, Validation Loss: 1.1235\n",
      "Epoch [10/100], Training Loss: 0.5250, Validation Loss: 1.1422\n",
      "Epoch [11/100], Training Loss: 0.8373, Validation Loss: 1.1163\n",
      "Epoch [12/100], Training Loss: 0.6426, Validation Loss: 1.0980\n",
      "Epoch [13/100], Training Loss: 0.8911, Validation Loss: 1.2045\n",
      "Epoch [14/100], Training Loss: 0.5684, Validation Loss: 1.1020\n",
      "Epoch [15/100], Training Loss: 0.7418, Validation Loss: 1.1065\n",
      "Stopping early due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "# Define the model, criterion, optimizer with L2 regularization\n",
    "input_size = len(train_features_array[0])\n",
    "rtr_mlp = MLP()\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(rtr_mlp.parameters(), lr=0.001, weight_decay=1e-5)  # Added L2 regularization\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Training loop with early stopping\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    rtr_mlp.train()  # Set model to training mode\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = rtr_mlp(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation phase\n",
    "    rtr_mlp.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for batch_features, batch_labels in val_loader:\n",
    "            outputs = rtr_mlp(batch_features)\n",
    "            val_loss += criterion(outputs, batch_labels).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Check early stopping condition\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Stopping early due to no improvement in validation loss.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "483064dc-daf2-41e1-a2d8-9f89ce8d0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(userId, query, movieId):\n",
    "    # Extract movie title from movieId\n",
    "    movie_title = movies[movies['movieId'] == movieId]['title'].iloc[0]\n",
    "    print(\"DEBUG info:\\n\", f'movie_title: {movie_title};\\n', f'query: {query};\\n', f'userId: {userId}\\n')\n",
    "    \n",
    "    # Generate feature vector (same method as used in training)\n",
    "    feature_vector = combine_features(query, userId, movie_title)\n",
    "    \n",
    "    # Convert the feature vector to a single numpy array before converting to a tensor\n",
    "    feature_tensor = torch.tensor(np.array([feature_vector]), dtype=torch.float32)\n",
    "\n",
    "    return feature_tensor\n",
    "\n",
    "def predict_score(userId, query, movieId):\n",
    "    rtr_mlp.eval()  # Set it to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients for prediction\n",
    "        input_features = prepare_features(userId, query, movieId)\n",
    "        output = rtr_mlp(input_features)\n",
    "        \n",
    "        # The output is a tensor, get the scalar value\n",
    "        predicted_score = output.item()\n",
    "\n",
    "    return predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58e50a7b-063e-4ff8-a298-c84982e944f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG info:\n",
      " movie_title: Toy Story (1995);\n",
      " query: Toy Story (1995);\n",
      " userId: 1\n",
      "\n",
      "Predicted Rating: 3.634709596633911\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "userId = 1  # Example userId\n",
    "query = \"Toy Story (1995)\"\n",
    "movieId = 1  # Example movieId\n",
    "\n",
    "    \n",
    "predicted_rating = predict_score(userId, query, movieId)\n",
    "print(f\"Predicted Rating: {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "555f915c-de4a-4a8e-a06d-7d3804268796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.366379</td>\n",
       "      <td>0.800048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.948276</td>\n",
       "      <td>0.805615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.435897</td>\n",
       "      <td>2.090642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>1.314204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>0.990441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  avg_rating  rating_stddev\n",
       "0       1    4.366379       0.800048\n",
       "1       2    3.948276       0.805615\n",
       "2       3    2.435897       2.090642\n",
       "3       4    3.555556       1.314204\n",
       "4       5    3.636364       0.990441"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(user_stats.head())\n",
    "display(movies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd242a3-1ae9-4ba2-8c3e-d4aaa37bf99a",
   "metadata": {},
   "source": [
    "## save features and model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9647fd4c-4486-4d30-a3e9-54084585cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to a CSV file with header\n",
    "# user_stats.to_csv('../data/feature-store/user_stats.csv', header=True, index=False)\n",
    "# movies.to_csv('../data/feature-store/movies.csv', header=True, index=False)\n",
    "# Save the trained model\n",
    "# torch.save(rtr_mlp.state_dict(), '../model-artifacts/mlp_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dcf664-11c0-42bf-8803-658c7b976383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use DistilBert tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = encoder(**inputs)\n",
    "    # DistilBERT does not output the 'pooler_output' so use mean of last hidden state\n",
    "    return outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Define the MLP model class\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Function to generate the combined features\n",
    "def combine_features(query, user_id, movie_title):\n",
    "    query_emb = get_bert_embedding(query).detach().numpy().flatten()\n",
    "    user_avg, user_std = user_stats[user_stats['userId'] == user_id][['avg_rating', 'rating_stddev']].iloc[0]\n",
    "    movie_emb = get_bert_embedding(movie_title).detach().numpy().flatten()\n",
    "    \n",
    "    combined = np.concatenate([query_emb, [user_avg, user_std], movie_emb])\n",
    "    return combined\n",
    "\n",
    "# Function to prepare input features for the model\n",
    "def prepare_features(userId, query, movieId):\n",
    "    # Extract movie title from movieId\n",
    "    movie_title = movies[movies['movieId'] == movieId]['title'].iloc[0]\n",
    "    print(\"DEBUG info:\\n\", f'movie_title: {movie_title};\\n', f'query: {query};\\n', f'userId: {userId}\\n')\n",
    "    \n",
    "    # Generate feature vector\n",
    "    feature_vector = combine_features(query, userId, movie_title)\n",
    "    \n",
    "    # Convert the feature vector to a tensor\n",
    "    feature_tensor = torch.tensor(np.array([feature_vector]), dtype=torch.float32)\n",
    "\n",
    "    return feature_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c124d1-7629-4f18-bdf9-18f34d6417a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(model, userId, query, movieId):\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients for prediction\n",
    "        input_features = prepare_features(userId, query, movieId)\n",
    "        output = model(input_features)\n",
    "        \n",
    "        # The output is a tensor, get the scalar value\n",
    "        predicted_score = output.item()\n",
    "    \n",
    "    return predicted_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a525001-55df-4e1f-8b57-e312d9384d55",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bd8c96-134d-40c7-ae0a-17485cf18f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=1538, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new instance of your MLP model\n",
    "input_size = 768 * 2 + 2 # Example size: 2 * BERT embeddings + user avg and stddev\n",
    "\n",
    "loaded_model = MLP(input_size)\n",
    "\n",
    "# Load the model's state dictionary\n",
    "loaded_model.load_state_dict(torch.load('../model-artifacts/mlp_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa9e20-bf5e-4989-9d2a-09f08cb60010",
   "metadata": {},
   "source": [
    "## load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb79a4cb-5bff-4bf5-ab41-da2cd29fde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stats = pd.read_csv('../data/feature-store/user_stats.csv')\n",
    "\n",
    "movies = pd.read_csv('../data/feature-store/movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656db071-1fd7-480e-9462-a4f4df9b81f0",
   "metadata": {},
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2457ffeb-81b4-4df2-8d97-33185c78f6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG info:\n",
      " movie_title: Bottle Rocket (1996);\n",
      " query: example query;\n",
      " userId: 1\n",
      "\n",
      "Predicted Score: 3.241020441055298\n"
     ]
    }
   ],
   "source": [
    "user_id = 1\n",
    "query = \"example query\"\n",
    "movie_id = 101\n",
    "score = predict_score(loaded_model, user_id, query, movie_id)\n",
    "print(\"Predicted Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0070a8-b523-4d28-82bb-d3bc01394a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-model",
   "language": "python",
   "name": "ml-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
