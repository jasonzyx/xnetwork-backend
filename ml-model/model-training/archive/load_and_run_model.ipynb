{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # accessing directory structure\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import faiss \n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = \"../model-artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "faiss_index = faiss.read_index(f\"{path_prefix}/faiss_index.idx\")\n",
    "tokenizer = BertTokenizer.from_pretrained(f\"{path_prefix}/bert_model\")\n",
    "encoder = BertModel.from_pretrained(f\"{path_prefix}/bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_prefix}/index_to_id.pickle\", 'rb') as handle:\n",
    "    index_to_id = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(query, k, faiss_index, index_to_id, tokenizer, encoder):\n",
    "    query_embedding = encode_query(query, tokenizer, encoder)\n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "\n",
    "    # Retrieve movie IDs for the indices\n",
    "    return [(index_to_id[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "\n",
    "\n",
    "def encode_titles_batch(titles, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(titles), batch_size):\n",
    "        batch = titles[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        outputs = encoder(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "        all_embeddings.append(embeddings)\n",
    "\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(titles) // batch_size + 1}\")\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    return all_embeddings\n",
    "\n",
    "def encode_query(query, tokenizer, encoder):\n",
    "    inputs = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    outputs = encoder(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((405,\n",
       "   'Highlander III: The Sorcerer (a.k.a. Highlander: The Final Dimension) (1994)'),\n",
       "  47.149372),\n",
       " ((32, 'Twelve Monkeys (a.k.a. 12 Monkeys) (1995)'), 45.424206),\n",
       " ((47, 'Seven (a.k.a. Se7en) (1995)'), 45.41999),\n",
       " ((293, 'Léon: The Professional (a.k.a. The Professional) (Léon) (1994)'),\n",
       "  44.40825),\n",
       " ((366,\n",
       "   \"Wes Craven's New Nightmare (Nightmare on Elm Street Part 7: Freddy's Finale, A) (1994)\"),\n",
       "  43.299595),\n",
       " ((83, 'Once Upon a Time... When We Were Colored (1995)'), 42.53481),\n",
       " ((284, 'New York Cop (Nyû Yôku no koppu) (1993)'), 41.428364),\n",
       " ((112, 'Rumble in the Bronx (Hont faan kui) (1995)'), 40.592518),\n",
       " ((154, 'Beauty of the Day (Belle de jour) (1967)'), 40.41004),\n",
       " ((63,\n",
       "   \"Don't Be a Menace to South Central While Drinking Your Juice in the Hood (1996)\"),\n",
       "  39.788284)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_index('toy story', 10, faiss_index, index_to_id, tokenizer, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7181,
     "sourceId": 10279,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29271,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ml-model",
   "language": "python",
   "name": "ml-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
